apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "ollama.fullname" . }}
  namespace: {{ include "ollama.namespace" . }}
  labels:
    {{- include "ollama.labels" . | nindent 4 }}
spec:
  replicas: {{ .Values.replicaCount | default 1 }}
  selector:
    matchLabels:
      {{- include "ollama.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "ollama.labels" . | nindent 8 }}
      annotations:
        # Force pod restart on config changes
        checksum/config: {{ .Values.ollama | toYaml | sha256sum }}
        {{- with .Values.podAnnotations }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
    spec:
      serviceAccountName: {{ include "ollama.serviceAccountName" . }}
      securityContext:
        {{- toYaml .Values.podSecurityContext | nindent 8 }}
      initContainers:
        {{- include "ollama.modelPullInitContainer" . | nindent 8 }}
      containers:
        - name: ollama
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          command:
            - /bin/sh
            - -c
            - |
              echo "=== Starting Ollama Server ==="
              # Start Ollama server in background
              ollama serve &
              OLLAMA_PID=$!
              
              # Wait for server to be ready
              echo "Waiting for Ollama server to be ready..."
              until ollama list &> /dev/null; do
                echo "Waiting for Ollama server..."
                sleep 3
              done
              
              echo "Ollama server is ready!"
              
              # Pre-load the primary model for faster first requests
              echo "Pre-loading primary model: {{ .Values.ollama.model }}"
              if ollama list | grep -q "{{ .Values.ollama.model }}"; then
                echo "Model {{ .Values.ollama.model }} is available, pre-loading..."
                # Send a simple request to load the model into memory
                echo "Loading model into memory..." 
                ollama generate {{ .Values.ollama.model }} "Hello" --silent || echo "Model pre-load attempt completed"
                echo "Model pre-load completed"
              else
                echo "WARNING: Model {{ .Values.ollama.model }} not found in model list"
                ollama list
              fi
              
              echo "=== Ollama Server fully ready ==="
              
              # Keep the server running
              wait $OLLAMA_PID
          ports:
            - name: http
              containerPort: {{ .Values.ollama.port | default 11434 }}
              protocol: TCP
            {{- if .Values.monitoring.enabled }}
            - name: metrics
              containerPort: {{ .Values.monitoring.port | default 11434 }}
              protocol: TCP
            {{- end }}
          env:
            {{- toYaml .Values.ollama.env | nindent 12 }}
            {{- if .Values.huggingface.token }}
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: {{ include "ollama.fullname" . }}-hf-token
                  key: token
            {{- end }}
          volumeMounts:
            {{- if .Values.storage.enabled }}
            - name: ollama-storage
              mountPath: /root/.ollama
            {{- else }}
            - name: ollama-data
              mountPath: /root/.ollama
            {{- end }}
            {{- with .Values.ollama.additionalVolumeMounts }}
            {{- toYaml . | nindent 12 }}
            {{- end }}
          {{- if .Values.healthCheck.enabled }}
          livenessProbe:
            httpGet:
              path: {{ .Values.healthCheck.liveness.path }}
              port: http
            initialDelaySeconds: {{ .Values.healthCheck.liveness.initialDelaySeconds }}
            periodSeconds: {{ .Values.healthCheck.liveness.periodSeconds }}
            timeoutSeconds: {{ .Values.healthCheck.liveness.timeoutSeconds }}
            failureThreshold: {{ .Values.healthCheck.liveness.failureThreshold }}
          readinessProbe:
            httpGet:
              path: {{ .Values.healthCheck.readiness.path }}
              port: http
            initialDelaySeconds: {{ .Values.healthCheck.readiness.initialDelaySeconds }}
            periodSeconds: {{ .Values.healthCheck.readiness.periodSeconds }}
            timeoutSeconds: {{ .Values.healthCheck.readiness.timeoutSeconds }}
            failureThreshold: {{ .Values.healthCheck.readiness.failureThreshold }}
          startupProbe:
            httpGet:
              path: {{ .Values.healthCheck.startup.path }}
              port: http
            initialDelaySeconds: {{ .Values.healthCheck.startup.initialDelaySeconds }}
            periodSeconds: {{ .Values.healthCheck.startup.periodSeconds }}
            timeoutSeconds: {{ .Values.healthCheck.startup.timeoutSeconds }}
            failureThreshold: {{ .Values.healthCheck.startup.failureThreshold }}
          {{- end }}
          resources:
            {{- toYaml .Values.resources | nindent 12 }}
          securityContext:
            {{- toYaml .Values.securityContext | nindent 12 }}
      volumes:
        {{- if .Values.storage.enabled }}
        - name: ollama-storage
          persistentVolumeClaim:
            claimName: {{ include "ollama.fullname" . }}-pvc
        {{- else }}
        - name: ollama-data
          emptyDir: {}
        {{- end }}
        {{- with .Values.ollama.additionalVolumes }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
