{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ vLLM vs TGI vs Ollama: Low-Latency Chat Benchmarking\n",
        "\n",
        "[![OpenShift](https://img.shields.io/badge/Platform-OpenShift-red)](https://www.redhat.com/en/technologies/cloud-computing/openshift)\n",
        "[![vLLM](https://img.shields.io/badge/Engine-vLLM-blue)](https://github.com/vllm-project/vllm)\n",
        "[![TGI](https://img.shields.io/badge/Engine-TGI-orange)](https://github.com/huggingface/text-generation-inference)\n",
        "[![Ollama](https://img.shields.io/badge/Engine-Ollama-green)](https://github.com/ollama/ollama)\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Welcome to the Interactive Benchmarking Demo\n",
        "\n",
        "This notebook demonstrates **vLLM's superior performance** for low-latency chat applications through a comprehensive three-way comparison with TGI and Ollama.\n",
        "\n",
        "### What You'll Experience\n",
        "- **‚ö° Real-time performance metrics** - TTFT, ITL, E2E latency\n",
        "- **üìä Interactive visualizations** - Live charts and comparisons\n",
        "- **üîß Configuration insights** - Optimization techniques and best practices\n",
        "- **üéÆ Hands-on benchmarking** - Run your own tests and see immediate results\n",
        "\n",
        "### Target Metrics\n",
        "| Metric | Target | vLLM Expected |\n",
        "|--------|--------|---------------|\n",
        "| **TTFT** | < 100ms | ‚úÖ ~50-80ms |\n",
        "| **P95 Latency** | < 1 second | ‚úÖ ~300-600ms |\n",
        "| **Throughput** | 50+ users | ‚úÖ 100+ users |\n",
        "\n",
        "---\n",
        "\n",
        "**‚è±Ô∏è Demo Duration:** ~15-20 minutes  \n",
        "**üèóÔ∏è Infrastructure:** OpenShift with GPU nodes  \n",
        "**ü§ñ Model:** Qwen/Qwen2.5-7B (standardized across all engines)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìã Section 1: Introduction & Architecture\n",
        "\n",
        "Understanding the benchmarking environment and what makes this comparison meaningful.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úÖ Environment setup complete!</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[32m‚úÖ Environment setup complete!\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">üìÅ Project root: /Users/gsampaio/redhat/ai/vllm-notebooks</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[34müìÅ Project root: \u001b[0m\u001b[34m/Users/gsampaio/redhat/ai/\u001b[0m\u001b[34mvllm-notebooks\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">üìä Results will be saved to: /Users/gsampaio/redhat/ai/vllm-notebooks/results</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[34müìä Results will be saved to: \u001b[0m\u001b[34m/Users/gsampaio/redhat/ai/vllm-notebooks/\u001b[0m\u001b[34mresults\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Core imports and setup\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import asyncio\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# Data processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# HTTP clients\n",
        "import requests\n",
        "import httpx\n",
        "\n",
        "# Kubernetes/OpenShift\n",
        "try:\n",
        "    from kubernetes import client, config\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Kubernetes client not available - using fallback mode\")\n",
        "\n",
        "# Rich console output\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "from rich.progress import Progress\n",
        "from rich.panel import Panel\n",
        "\n",
        "# Initialize console\n",
        "console = Console()\n",
        "\n",
        "# Project paths\n",
        "PROJECT_ROOT = Path.cwd().parent\n",
        "DATA_DIR = PROJECT_ROOT / \"data\"\n",
        "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
        "\n",
        "# Create results directory\n",
        "RESULTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "console.print(\"[green]‚úÖ Environment setup complete![/green]\")\n",
        "console.print(f\"[blue]üìÅ Project root: {PROJECT_ROOT}[/blue]\")\n",
        "console.print(f\"[blue]üìä Results will be saved to: {RESULTS_DIR}[/blue]\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
